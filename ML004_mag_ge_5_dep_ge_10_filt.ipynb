{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## DOCUMENTATION  \n",
        "this is just the initial documenatation whcih will be improved once we integrate in Github"
      ],
      "metadata": {
        "id": "_jeXJaOWO7C2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRPIUXl4pbiV"
      },
      "outputs": [],
      "source": [
        "# Date        Initials    Description\n",
        "# 10FEB2023   PN          - Initial Library, USGS Load for 2023, 48 Philippines stations, 50/10 data extract, RasberryShape Data Extract loop\n",
        "\n",
        "\n",
        "#Future add ASAP (as of 5 April 2024)\n",
        "# MMF 3 year data extract loop, Initial Arima, K-Mean, and LSTM model mode, Log/Lat extraction for each station, and Closest 5 stations to eartquake loop\n",
        "# PN STA and LTA features, Auto Trigger function"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial PIP installation\n"
      ],
      "metadata": {
        "id": "FK-_g8kxPK3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install obspy # enable line when using temporary notebook/instance\n",
        "# ! mkdir /content/rs-usgs-test\n",
        "# ! cd /content/rs-usgs-test && gdown https://drive.google.com/uc?id=1K4ivaWZBZi_26JmFwqOH1GP2q8jO15Rv"
      ],
      "metadata": {
        "id": "3EU8Qw_pOIln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instance information for any diagnostics use\n",
        "\n",
        "! python --version\n",
        "! nproc"
      ],
      "metadata": {
        "id": "iLqhJzrNpcxX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4f0b381-c643-49ed-e8fe-24dc01f20f67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Library Imports"
      ],
      "metadata": {
        "id": "7SYeJnjGPRrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import obspy\n",
        "\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "\n",
        "from obspy.clients.fdsn import Client\n",
        "from obspy.core import UTCDateTime, Stream, Trace\n",
        "from obspy.imaging.maps import plot_cartopy as plt_crt\n",
        "\n",
        "import os\n",
        "import threading\n",
        "import time\n",
        "\n",
        "from concurrent.futures import ThreadPoolExecutor as ccf_tpe\n",
        "from concurrent.futures import ProcessPoolExecutor as ccf_ppe"
      ],
      "metadata": {
        "id": "eLp0uvGqpeOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading USGS Dataset with every earthquake"
      ],
      "metadata": {
        "id": "lnkGPqvwTlvS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please make sure to add the \"assets\" folder in the same folder as ML004 notebook"
      ],
      "metadata": {
        "id": "uM5LeU9c7R4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#usgs_data = '/content/rs-usgs-test/DS001_USGS_dataset 1950-2023.csv'\n",
        "usgs_data = 'assets/DS001_USGS_dataset 1950-2023.csv'\n",
        "\n",
        "usgs_df = pd.read_csv(usgs_data)                # loads csv to dataframe\n",
        "usgs_df.time = pd.to_datetime(usgs_df.time)     # convert object type to datetime64\n",
        "\n",
        "year_lim = 2023\n",
        "\n",
        "usgs_df_lim = usgs_df[usgs_df.time.dt.year >= year_lim]\n",
        "usgs_df_lim.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "KyAx1US3pj-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered = usgs_df_lim[(usgs_df_lim['mag'] >= 5) & (usgs_df_lim['depth'] <= 10)].reset_index()\n",
        "filtered.columns"
      ],
      "metadata": {
        "id": "Je15AoRypw1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manually finding the Rasberry Shakestations in the Philippines"
      ],
      "metadata": {
        "id": "ufqFkwjvTrkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stations_luzon = ['R1EFC',\n",
        "                'S050E',\n",
        "                'R061D',\n",
        "                'RE7F4',\n",
        "                'R3B2D',\n",
        "                'R6423',\n",
        "                'R5160',\n",
        "                'R67F1',\n",
        "                'RD61C',\n",
        "                'R5595',\n",
        "                'R1CB3',\n",
        "                'R3F4D',\n",
        "                'R1CB3',\n",
        "                'S6A6F',\n",
        "                'RA66D',\n",
        "                'R2960',\n",
        "                'R1201',\n",
        "                'RC58C',\n",
        "                'R3A55',\n",
        "                'R3282',\n",
        "                'RE63C',\n",
        "                'R4F2C',\n",
        "                'RD4DD',\n",
        "                'R191E',\n",
        "                'R5744',\n",
        "                'RC8A0',\n",
        "                'R9912',\n",
        "                'RBBDE',\n",
        "                'R1E7D',\n",
        "                'R91E4',\n",
        "                'S690A',\n",
        "                'R98E0',\n",
        "                'R8095'] # last station for Luzon is in CamSur\n",
        "\n",
        "stations_visayas = ['R257C',\n",
        "                    'R9829',\n",
        "                    'R9CAE',\n",
        "                    'R402F',\n",
        "                    'R23C6',\n",
        "                    'REA68',\n",
        "                    'R4C3D',\n",
        "                    'RF17C'] # last station for Visayas is in Naga\n",
        "\n",
        "\n",
        "\n",
        "stations_mindanao = ['REBEA',\n",
        "                     'R2B9C',\n",
        "                     'RD5D8',\n",
        "                     'RF8C0',\n",
        "                     'R4893',\n",
        "                     'R1382',\n",
        "                     'RBD68'] # last station in Mindanao is in Tulunan\n",
        "\n",
        "\n",
        "stations = stations_luzon + stations_visayas + stations_mindanao"
      ],
      "metadata": {
        "id": "XWRdaYu4pz93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Taking 50 minutes before and 10 minutes after"
      ],
      "metadata": {
        "id": "2VAozrSIT-7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## taking 50 minutes before and 10 minutes after\n",
        "t_start : int = 3000\n",
        "t_end   : int = 600\n",
        "\n",
        "event : float = UTCDateTime(usgs_df.time[0].year,\n",
        "                    usgs_df.time[0].month,\n",
        "                    usgs_df.time[0].day,\n",
        "                    usgs_df.time[0].hour,\n",
        "                    usgs_df.time[0].minute,\n",
        "                    usgs_df.time[0].second)\n",
        "\n",
        "start : float = event - t_start\n",
        "end : float   = event + t_end"
      ],
      "metadata": {
        "id": "UnwvPiZPp1WM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get station metadata and put into df\n",
        "rs = Client('RASPISHAKE')\n",
        "net = 'AM'\n",
        "channels = ['EHZ', 'HDF','ENE','ENN', 'ENZ']\n",
        "stream = Stream()"
      ],
      "metadata": {
        "id": "w0NngC_Up2TY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Rasberryshake Data from the 48 stations for every earthquake in USGS data"
      ],
      "metadata": {
        "id": "Ik1xcUtcUNpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ToFile(data, stations, filename, format):\n",
        "\n",
        "    t_start : int = 3000\n",
        "    t_end   : int = 600\n",
        "\n",
        "    rs = Client('RASPISHAKE')\n",
        "    net = 'AM'\n",
        "    channels = ['EHZ', 'HDF','ENE','ENN', 'ENZ']\n",
        "    stream = Stream()\n",
        "\n",
        "    NumEvents = data.index\n",
        "\n",
        "    for index in NumEvents:\n",
        "        event = UTCDateTime(data.time[index].year,\n",
        "                        data.time[index].month,\n",
        "                        data.time[index].day,\n",
        "                        data.time[index].hour,\n",
        "                        data.time[index].minute,\n",
        "                        data.time[index].second)\n",
        "\n",
        "        start : float = event - t_start\n",
        "        end : float   = event + t_end\n",
        "\n",
        "        for stn in stations:\n",
        "            for chan in channels:\n",
        "                try:\n",
        "                    trace = rs.get_waveforms(net, stn, '00', chan, start, end)\n",
        "                    stream += trace\n",
        "\n",
        "                except Exception: #HTTPError i.e. channel or station does not exist\n",
        "                    pass\n",
        "\n",
        "        stream.write(f'{filename}_{index}.pkl', format = format)\n",
        "\n"
      ],
      "metadata": {
        "id": "p3GpryR6p3Oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ToFile(data = filtered, stations = stations, filename = 'rsn_data', format = 'PICKLE')"
      ],
      "metadata": {
        "id": "zQK16Xw0p4YL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}